{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "toc_visible": true,
      "mount_file_id": "1mBzGnP20Q8FdZ9Zd4P5ncJnu2on5fhMX",
      "authorship_tag": "ABX9TyMmKBFyhkTvAoOsUQZJd1nQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jmmostafa/QAFMCB-Seminar/blob/main/Data_Analysis_Results_QACBFM_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "gKDDGrc3QMq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary installing libraries"
      ],
      "metadata": {
        "id": "umRkIzHFP4QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Setting the working directory\n",
        "# from google.colab import drive\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nVe8x0SLjXJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install them before use\n",
        "!pip install scienceplots --quiet\n",
        "!pip install PyPDF2 --quiet\n",
        "!pip install stargazer --quiet"
      ],
      "metadata": {
        "id": "yQXVsU_AmW0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "bLkbKbCMQFOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubuTm_9Whjfj"
      },
      "outputs": [],
      "source": [
        "# loadin the library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import scienceplots\n",
        "import seaborn as sns\n",
        "# plt.style.use(\"ggplot\")\n",
        "# plt.style.use(\"classic\")\n",
        "# plt.style.use('seaborn-white')\n",
        "# plt.style.use(['science', 'notebook', 'grid'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "- Loading the data from the Drive (saved as csv files).\n",
        "- For analysis, take the latest cleaning sentiment scores as the t-test result shows that there is no significant difference in the word count in the two ways. However, as the last NS_Sentiment_Clean_PP --at first delete the propernouns before making it lowers and drop the stopwords mentioned in the 'nltk' package."
      ],
      "metadata": {
        "id": "QfHX9KUVmyAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from the drive\n",
        "lm_dict = pd.read_csv(\"/content/drive/MyDrive/QACFM Data/lm_dictionary_1993-2021.csv\")\n",
        "df_text = pd.read_csv(\"/content/drive/MyDrive/QACFM Data/df_ps_ng_sentiment_final.csv\", index_col ='Date')\n",
        "df_market = pd.read_csv(\"/content/drive/MyDrive/QACFM Data/df_market_vars.csv\", index_col = 'Date')\n",
        "\n",
        "# copying the into new df for further analysis\n",
        "df_text_sent = df_text.copy()\n",
        "df_market_data = df_market.copy()\n",
        "df_market_data.index = pd.to_datetime(df_market_data.index)\n",
        "\n",
        "# See the head of the datasets\n",
        "df_text_sent.head()\n",
        "df_market_data.head()"
      ],
      "metadata": {
        "id": "NAdCDc-xmwko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary Actions"
      ],
      "metadata": {
        "id": "kocLznofUjRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only take the necessary columns of each datasets and make other adjustments\n",
        "\n",
        "# for the text\n",
        "df_sent_vars = df_text_sent.iloc[:, list(range(7)) + list(range(14, 19))]\n",
        "df_sent_vars = pd.DataFrame(df_sent_vars.drop(columns = ['original_text']))\n",
        "df_sent_vars = df_sent_vars[df_sent_vars.index > '1999-12-01']\n",
        "df_sent_vars.index = pd.to_datetime(df_sent_vars.index)\n",
        "\n",
        "\n",
        "# for the market variables\n",
        "df_mkt_vars = df_market_data.filter(regex='[tTF]')\n",
        "drop_list = ['UMCSENT','CPILFESL','EPU_PCT','GDP_DFLTR','GDP_DFLTR_PCT','PCT_Export_GDP','EURO_STOXX50','USTB10','EUTB10','FEDTR']\n",
        "df_mkt_vars = pd.DataFrame(df_mkt_vars.drop(columns = drop_list))\n",
        "\n",
        "# df_mkt_vars[['FEDFUNDS','ECBMLFR','T10Y3M']].diff()\n",
        "# df_mkt_vars.info()\n",
        "# df_sent_vars.info()"
      ],
      "metadata": {
        "id": "NjB1JW6sRvpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Statistics"
      ],
      "metadata": {
        "id": "sKgsZzYUQq7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "# Alternatively, to suppress all warnings (not recommended for general use):\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "summary_results = []\n",
        "\n",
        "for column in df_mkt_vars.columns:\n",
        "    # ADF Test\n",
        "    adf_result = adfuller(df_mkt_vars[column])\n",
        "    # KPSS Test\n",
        "    kpss_result = kpss(df_mkt_vars[column], regression='c')\n",
        "    # Summary Stats\n",
        "    summary_stats = df_mkt_vars[column].describe()\n",
        "\n",
        "    summary_results.append({\n",
        "        'Series': column,\n",
        "        'Count': round(summary_stats['count'],0),\n",
        "        'Min': round(summary_stats['min'],3),\n",
        "        'Mean': round(summary_stats['mean'],3),\n",
        "        'Std Dev': round(summary_stats['std'],3),\n",
        "        'Max': round(summary_stats['max'],3),\n",
        "        'ADF Statistic': round(adf_result[0],3),\n",
        "        'ADF p-value': round(adf_result[1],3),\n",
        "        'KPSS Statistic': round(kpss_result[0],3),\n",
        "        'KPSS p-value': round(kpss_result[1],3)\n",
        "        # ... Add other summary stats as needed\n",
        "    })\n",
        "\n",
        "summary_results = pd.DataFrame(summary_results)\n",
        "\n",
        "\n",
        "# as the adf and KPSS p values are less than 10%, means we reject the null hypothesis.\n",
        "# That means, our time series are not non-stationary (not having any unit-root) rather they are stationary. it makes sense as we have used the percentage rather than real values (built in first difference).\n",
        "\n",
        "# Function to determine significance\n",
        "def significance_stars(p_value):\n",
        "    if p_value < 0.01:\n",
        "        return '***'\n",
        "    elif p_value < 0.05:\n",
        "        return '**'\n",
        "    elif p_value <= 0.1:\n",
        "        return '*'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def significance_stars_kpss(p_value):\n",
        "    if p_value < 0.01:\n",
        "        return '***'\n",
        "    elif p_value < 0.05:\n",
        "        return '**'\n",
        "    elif p_value <= 0.10:\n",
        "        return '*'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to each p-value column and create a combined column\n",
        "columns_to_check_adf = ['ADF p-value']  # Add other columns as needed\n",
        "columns_to_check_kpss = ['KPSS p-value']  # Add other columns as needed\n",
        "\n",
        "summary_results['ADF_Sig'] = summary_results[columns_to_check_adf].applymap(significance_stars).agg(''.join, axis=1)\n",
        "summary_results['KPSS_Sig'] = summary_results[columns_to_check_kpss].applymap(significance_stars_kpss).agg(''.join, axis=1)\n",
        "\n",
        "summary_results.to_csv('/content/drive/MyDrive/QACFM Data/Summary_Stat.csv', index=False)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "summary_results.head(3)"
      ],
      "metadata": {
        "id": "d-h96YlcHhif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking VIFs (Initially)"
      ],
      "metadata": {
        "id": "BeAadSvWQ0sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "# Calculating VIF for each variable\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Variable\"] = df_mkt_vars.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df_mkt_vars.values, i) for i in range(df_mkt_vars.shape[1])]\n",
        "print(vif)"
      ],
      "metadata": {
        "id": "TbzM0LME32xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Difference in Series"
      ],
      "metadata": {
        "id": "2zUB3mLACT1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind\n",
        "import numpy as np\n",
        "\n",
        "# Performing t-test\n",
        "t_statistic, p_value = ttest_ind(df_sent_vars['NG_Sentiment_org'], df_sent_vars['NG_Sentiment_clean_pp'])\n",
        "\n",
        "# Display the results\n",
        "print(f'T-statistic: {t_statistic}')\n",
        "print(f'P-value: {p_value}')\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the two series.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two series.\")\n"
      ],
      "metadata": {
        "id": "grLp7h42F0UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Figures"
      ],
      "metadata": {
        "id": "FEcIcajGR2bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Negative Sentiment in Original text and Cleaned one"
      ],
      "metadata": {
        "id": "TuAkugjxCclx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300)\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "fig.patch.set_facecolor('white')\n",
        "ax.set_facecolor('white')\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "df_sent_vars['NG_Sentiment_org'].plot(linestyle='-', marker='o', color='blue', label='NG_Sentiment_org', ax=ax)\n",
        "df_sent_vars['NG_Sentiment_clean_pp'].plot(linestyle='-', marker='*', color='red', label='NG_Sentiment_Clean_pp', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "# plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel('Negative Sentiment [Original Text]', color='blue', fontsize=12)\n",
        "ax.right_ax.set_ylabel('Negative Sentiment [Cleaned Text]', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.3, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.3, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.3, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(True, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/1. Negative_Tone_Fed_Org_Clean_pp.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PHLuKYz61VAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positive Tone Sentiment of Original text and Cleaned Text"
      ],
      "metadata": {
        "id": "vQCr0KGQMwOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300, facecolor='white', edgecolor='none')\n",
        "\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "df_sent_vars['PS_Sentiment_org'].plot(linestyle='-', marker='o', color='blue', label='PS_Sentiment_org', ax=ax)\n",
        "df_sent_vars['PS_Sentiment_clean_pp'].plot(linestyle='-', marker='*', color='red', label='PS_Sentiment_Clean_pp', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "# plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel('Positive Sentiment [Original Text]', color='blue', fontsize=12)\n",
        "ax.right_ax.set_ylabel('Positive Sentiment [Cleaned Text]', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.3, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.3, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.3, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(False, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/2. Positive_Tone_Fed_Org_Clean_pp.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XgrQti3--fRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative and Positive in the Cleaned Text"
      ],
      "metadata": {
        "id": "sKU2PsBoM--S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300, facecolor='white', edgecolor='none')\n",
        "\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "df_sent_vars['PS_Sentiment_clean_pp'].plot(linestyle='--', marker='o', color='blue', label='PS_Sentiment_org', ax=ax)\n",
        "df_sent_vars['NG_Sentiment_clean_pp'].plot(linestyle='-', marker='*', color='red', label='NG_Sentiment_Clean_pp', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "# plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel('Positive Sentiment Score', color='blue', fontsize=12)\n",
        "ax.right_ax.set_ylabel('Negative Sentiment Score', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.4, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.4, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.4, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(False, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/3. Positive_Negative_Tone_Fed_Org_Clean_pp.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V6gfUzz_U-iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative Sentiment and Stock market reactions"
      ],
      "metadata": {
        "id": "khmpjg2aIM2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300, facecolor='white', edgecolor='none')\n",
        "\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "np.log(df_market_data[['S&P 500','EURO_STOXX50','DAX30']]).plot(linestyle=':', marker='', color=['darkblue','#008000','black'], label='S&P500 Index', ax=ax)\n",
        "df_sent_vars['NG_Sentiment_clean_pp'].plot(linestyle='-', marker='o', color='red', label='NG_Sentiment_Clean_pp', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "# plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel('Log Distribution of Indices', color='black', fontsize=12)\n",
        "ax.right_ax.set_ylabel('Negative Sentiment Score', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.4, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.4, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.4, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(False, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Show only the legend for 'Y1'\n",
        "ax.legend(loc = 'lower right', labels=['S&P 500','EUROSTOXX 50','DAX30'], fontsize = 11, framealpha=0)\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/4. FED_Tone_SnP500_EUROSTOX50_DAX30.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mzg6vCAzOnjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fed and ECB Rate with Negative Tone Sentiment"
      ],
      "metadata": {
        "id": "4GXgg0RXSbUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300, facecolor='white', edgecolor='none')\n",
        "\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "df_mkt_vars[['FEDFUNDS','ECBMLFR']].plot(linestyle='-', marker='.', color=['darkblue','#008000'], ax = ax)\n",
        "# np.log(df_market_data[['S&P 500','EURO_STOXX50','DAX30']]).plot(linestyle=':', marker='', color=['darkblue','#008000','black'], label='S&P500 Index', ax=ax)\n",
        "df_sent_vars['NG_Sentiment_clean_pp'].plot(linestyle='-', marker='o', color='red', label='NG_Sentiment_Clean_pp', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "# plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel('Fund Rate (%)', color='black', fontsize=12)\n",
        "ax.right_ax.set_ylabel('Negative Sentiment Score', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.4, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.4, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.4, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(False, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Show only the legend for 'Y1'\n",
        "ax.legend(loc = 'lower left', labels=['FEDFUNDS','ECBMLFR'], fontsize = 11, framealpha=0)\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/5. Fed_Ecb_Tone_sentiment.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R2eUlpscINYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fed and ECB rate"
      ],
      "metadata": {
        "id": "kBYtnK1VSxcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.dates as mdates\n",
        "\n",
        "# # Assuming df_mkt_vars is your DataFrame with the necessary columns\n",
        "# plt.figure(figsize=(12, 8), dpi=300, facecolor = 'white', edgecolor='white')\n",
        "# plt.style.use(['science', 'notebook', 'grid'])\n",
        "\n",
        "# # Plotting\n",
        "# df_mkt_vars[['FEDFUNDS','ECBMLFR']].plot(linestyle='-', marker='.', color=['darkblue','#008000'])\n",
        "\n",
        "# # Set labels\n",
        "# plt.ylabel('Fund rate (%)', color='black', fontsize=12)\n",
        "# plt.xlabel(\"\", fontsize=12)\n",
        "\n",
        "# # Shaded regions\n",
        "# x_dotcom_b = \"2001-03-01\"\n",
        "# x_dotcom_e = \"2001-11-30\"\n",
        "# x_gfc_b = \"2007-12-01\"\n",
        "# x_gfc_e = \"2009-06-30\"\n",
        "# x_covid_b = \"2020-02-01\"\n",
        "# x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# # Shade regions\n",
        "# plt.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.4, label='Dotcom')\n",
        "# plt.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.4, label='GFC')\n",
        "# plt.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.4, label='COVID-19')\n",
        "\n",
        "# # Customize the grid\n",
        "# plt.grid(True, linestyle='', alpha=0)\n",
        "\n",
        "# # Set x-axis ticks at 3-year intervals\n",
        "# plt.gca().xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# # Legend\n",
        "# plt.legend(loc = 'upper right', labels=['FEDFUNDR','ECBLR'],fontsize = 11, framealpha=0)\n",
        "\n",
        "# # Reduce font size of tick labels\n",
        "# plt.tick_params(axis='both', which='major', labelsize=15)\n",
        "\n",
        "# # Use tight_layout for better spacing\n",
        "# plt.tight_layout()\n",
        "\n",
        "# # Saving the graph in the specified directory\n",
        "# # plt.savefig('/content/drive/MyDrive/QACFM Data/5. FED_ECB_RATE_TONE.png')  # Modify the path as necessary\n",
        "\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "zPnsE-VfjeoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Analysis"
      ],
      "metadata": {
        "id": "scNuxXnUKWxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation among the variables"
      ],
      "metadata": {
        "id": "K-0koxFoS8Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a correlation heatmap using seaborn\n",
        "plt.figure(figsize=(12, 10), dpi=300, facecolor='white', edgecolor='none')\n",
        "sns.set(font_scale=0.9)\n",
        "\n",
        "# Create a heatmap with a diverging colormap\n",
        "sns.heatmap(df_mkt_vars.corr(), cmap='Spectral', cbar_kws={'fraction': 0.25}, vmin=-1, vmax=1)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/6. Correlation heatmap.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3e1jHVyz5o41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### S&P500 return distributions"
      ],
      "metadata": {
        "id": "SKba9vctTC0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Assuming df_mkt_vars is your DataFrame\n",
        "# df_mkt_vars = ...\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot histogram on a white background\n",
        "df_mkt_vars[\"S&P500_PCT\"].plot(kind=\"hist\", bins=100, density=True, color='blue', edgecolor='black', facecolor='white', label='Returns [GSPC]', fontsize=12)\n",
        "\n",
        "# Fit a normal distribution to the data\n",
        "mu, std = norm.fit(df_mkt_vars[\"S&P500_PCT\"])\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = norm.pdf(x, mu, std)\n",
        "plt.plot(x, p, 'k', linewidth=2, color=\"red\", label='$\\mu$ = {:.4f}, $\\sigma$ = {:.4f}'.format(mu, std))\n",
        "\n",
        "# Add labels and title\n",
        "plt.legend(loc=\"upper left\", fontsize=12)\n",
        "plt.xlabel(\"Daily Returns (S&P 500)\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.title(\"Return Distributions of GSPC\", fontsize=13)\n",
        "\n",
        "# Customize the grid\n",
        "plt.grid(True, linestyle='', alpha=0.5)\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/7. SnP500_returns Distributions.png')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_wlDS1xDYrHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating Changes in NG_Delta_Tau and PS_Delta_Phi"
      ],
      "metadata": {
        "id": "2nMctGZtfN2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with only event day with explanatory variables\n",
        "df_mkt_vars[['ECBMLFR_DFF','T10Y3M_DFF']] = df_mkt_vars.loc[:,['ECBMLFR','T10Y3M']].diff()\n",
        "df_sent_vars['NG_Delta_Tau'] = np.log(df_sent_vars['NG_Sentiment_clean_pp'].div(df_sent_vars['NG_Sentiment_clean_pp'].shift(1)))\n",
        "df_sent_vars['PS_Delta_Phi'] = np.log(df_sent_vars['PS_Sentiment_clean_pp'].div(df_sent_vars['PS_Sentiment_clean_pp'].shift(1)))\n",
        "df_reg_vars = pd.concat([df_sent_vars.iloc[:,9:13],df_mkt_vars],axis = 1).dropna()\n",
        "df_reg_vars.info()"
      ],
      "metadata": {
        "id": "QyLqG-DWOnfM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_reg_vars['NG_tone_sent_clean_pp'] = np.log(df_reg_vars['NG_Sentiment_clean_pp'].div(df_reg_vars['NG_Sentiment_clean_pp'].shift(1)))\n",
        "# df_reg_vars['PS_tone_sent_clean_pp'] = np.log(df_reg_vars['PS_Sentiment_clean_pp'].div(df_reg_vars['PS_Sentiment_clean_pp'].shift(1)))\n",
        "\n",
        "# df_reg_vars.dropna(inplace = True)\n",
        "# df_reg_vars.head()"
      ],
      "metadata": {
        "id": "TKOr3hVcy5Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary Stats for the updated data"
      ],
      "metadata": {
        "id": "5G-HaiVDYQSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "\n",
        "# Alternatively, to suppress all warnings (not recommended for general use):\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "summary_results_1 = []\n",
        "\n",
        "for column in df_reg_vars.columns:\n",
        "    # ADF Test\n",
        "    adf_result = adfuller(df_reg_vars[column])\n",
        "    # KPSS Test\n",
        "    kpss_result = kpss(df_reg_vars[column], regression='c')\n",
        "    # Summary Stats\n",
        "    summary_stats = df_reg_vars[column].describe()\n",
        "\n",
        "    summary_results_1.append({\n",
        "        'Series': column,\n",
        "        'Count': round(summary_stats['count'],0),\n",
        "        'Min': round(summary_stats['min'],3),\n",
        "        'Mean': round(summary_stats['mean'],3),\n",
        "        'Std Dev': round(summary_stats['std'],3),\n",
        "        'Max': round(summary_stats['max'],3),\n",
        "        'ADF Statistic': round(adf_result[0],3),\n",
        "        'ADF p-value': round(adf_result[1],3),\n",
        "        'KPSS Statistic': round(kpss_result[0],3),\n",
        "        'KPSS p-value': round(kpss_result[1],3)\n",
        "        # ... Add other summary stats as needed\n",
        "    })\n",
        "\n",
        "summary_results_1 = pd.DataFrame(summary_results_1)\n",
        "\n",
        "\n",
        "# as the adf and KPSS p values are less than 10%, means we reject the null hypothesis.\n",
        "# That means, our time series are not non-stationary (not having any unit-root) rather they are stationary. it makes sense as we have used the percentage rather than real values (built in first difference).\n",
        "\n",
        "# Function to determine significance\n",
        "def significance_stars(p_value):\n",
        "    if p_value < 0.01:\n",
        "        return '***'\n",
        "    elif p_value < 0.05:\n",
        "        return '**'\n",
        "    elif p_value <= 0.1:\n",
        "        return '*'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def significance_stars_kpss(p_value):\n",
        "    if p_value < 0.01:\n",
        "        return '***'\n",
        "    elif p_value < 0.05:\n",
        "        return '**'\n",
        "    elif p_value <= 0.10:\n",
        "        return '*'\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# Apply the function to each p-value column and create a combined column\n",
        "columns_to_check_adf = ['ADF p-value']  # Add other columns as needed\n",
        "columns_to_check_kpss = ['KPSS p-value']  # Add other columns as needed\n",
        "\n",
        "summary_results_1['ADF_Sig'] = summary_results_1[columns_to_check_adf].applymap(significance_stars).agg(''.join, axis=1)\n",
        "summary_results_1['KPSS_Sig'] = summary_results_1[columns_to_check_kpss].applymap(significance_stars_kpss).agg(''.join, axis=1)\n",
        "\n",
        "summary_results_1.to_csv('/content/drive/MyDrive/QACFM Data/Summary_Stat_1.csv', index=False)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "summary_results_1.head(3)"
      ],
      "metadata": {
        "id": "1uSYAvv9YVDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIF values for updated data"
      ],
      "metadata": {
        "id": "uM32966_UONU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming you have a DataFrame named 'df_reg_vars'\n",
        "\n",
        "# Specify the columns to exclude (0-based indices)\n",
        "exclude_columns = [0,1,4,5,8]\n",
        "\n",
        "# Get the remaining columns for VIF calculation\n",
        "selected_columns = df_reg_vars.columns[~df_reg_vars.columns.isin(df_reg_vars.columns[exclude_columns])]\n",
        "\n",
        "# Calculate VIF for each selected column\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = selected_columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df_reg_vars[selected_columns].values, i) for i in range(len(selected_columns))]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "nMk5P19a_gb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: EVENT DAY models using different controls: Without Interaction terms"
      ],
      "metadata": {
        "id": "Z0tApvhwixcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting Evolutions of $\\delta\\tau$ & $\\delta\\phi$"
      ],
      "metadata": {
        "id": "utwVQQ0OViCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Assuming df_sent_vars is your DataFrame with the necessary columns\n",
        "\n",
        "plt.style.use(['science', 'notebook', 'grid'])\n",
        "plt.figure(figsize=(12, 8), dpi=300, facecolor='white')\n",
        "\n",
        "# Plot with two y-axes\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Use the DataFrame's plot method directly for better readability\n",
        "df_reg_vars[['PS_Delta_Phi']].plot(linestyle='--', marker='.', color='blue', ax=ax)\n",
        "df_reg_vars[['NG_Delta_Tau']].plot(linestyle='-', marker='.', color='red', secondary_y=True, ax=ax)\n",
        "\n",
        "# Enable LaTeX rendering\n",
        "plt.rcParams['text.usetex'] = True\n",
        "\n",
        "# Set labels for both y-axes\n",
        "ax.set_ylabel(r'Changes in Postive Sentiment ($\\delta\\phi$)', color='blue', fontsize=12)\n",
        "ax.right_ax.set_ylabel(r'Changes in Negative Sentiment ($\\delta\\tau$)', fontsize=12, color='red')\n",
        "ax.set_xlabel(\"\", fontsize=12)\n",
        "\n",
        "\n",
        "# shaded regions\n",
        "x_dotcom_b = \"2001-03-01\"\n",
        "x_dotcom_e = \"2001-11-30\"\n",
        "x_gfc_b = \"2007-12-01\"\n",
        "x_gfc_e = \"2009-06-30\"\n",
        "x_covid_b = \"2020-02-01\"\n",
        "x_covid_e = \"2020-04-30\"\n",
        "\n",
        "# Shade regions\n",
        "ax.axvspan(x_dotcom_b, x_dotcom_e, facecolor='gray', alpha=0.4, label='Dotcom')\n",
        "ax.axvspan(x_gfc_b, x_gfc_e, facecolor='gray', alpha=0.4, label='GFC')\n",
        "ax.axvspan(x_covid_b, x_covid_e, facecolor='gray', alpha=0.4, label='COVID-19')\n",
        "# Add LaTeX text annotations\n",
        "# ax.text('2001-03-01', 0.976, r'DotCom', fontsize=10, ha='center', va='center', bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.5'))\n",
        "\n",
        "# Hide the legend\n",
        "ax.legend().set_visible(False)\n",
        "\n",
        "# Customize the grid\n",
        "ax.grid(True, linestyle='', alpha=0.8)\n",
        "\n",
        "# Set x-axis ticks at 3-year intervals\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(base=4))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Adjust the format as needed\n",
        "\n",
        "# Reduce font size of tick labels on both axes\n",
        "ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "ax.right_ax.tick_params(axis='both', which='both', labelsize=15)\n",
        "\n",
        "\n",
        "# Use tight_layout for better spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Set the background color of the entire figure\n",
        "ax.patch.set_facecolor('white')\n",
        "ax.spines['top'].set_visible(True)\n",
        "ax.spines['top'].set_visible(True)\n",
        "\n",
        "# saving the graph in the Drive folder\n",
        "plt.savefig('/content/drive/MyDrive/QACFM Data/6. NG_Tau_PS_phi.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UHYZsX3MIMLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models 01: $\\delta\\tau$ and $R_t$"
      ],
      "metadata": {
        "id": "2BxlHC6D2yBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# y-variables along\n",
        "y1_US =df_reg_vars['S&P500_PCT']\n",
        "y2_EU =df_reg_vars['EURO_STOXX50_PCT']\n",
        "\n",
        "# x-variables along with the models (model 1)\n",
        "X1_policy = df_reg_vars.loc[:,['NG_Delta_Tau','FEDFUNDS','ECBMLFR_DFF', 'MSIMZMP_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X1_policy = sm.add_constant(X1_policy)\n",
        "# Fit the OLS model\n",
        "model1 = sm.OLS(y1_US, X1_policy).fit()\n",
        "# print(model1.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "\n",
        "# model 2\n",
        "X2_macs = df_reg_vars.loc[:,['NG_Delta_Tau','GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X2_macs = sm.add_constant(X2_macs)\n",
        "# Fit the OLS model\n",
        "model2 = sm.OLS(y1_US, X2_macs).fit()\n",
        "# print(model2.summary())\n",
        "\n",
        "# ----------------------------------------------\n",
        "\n",
        "\n",
        "# model 3\n",
        "X3_exts = df_reg_vars.loc[:,['NG_Delta_Tau','USD_EURO_PCT','EUTB10_PCT','EURO_STOXX50_PCT','DAX30_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X3_exts = sm.add_constant(X3_exts)\n",
        "# Fit the OLS model\n",
        "model3 = sm.OLS(y1_US, X3_exts).fit()\n",
        "# print(model3.summary())\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "\n",
        "# model 4\n",
        "X4_vol = df_reg_vars.loc[:,['NG_Delta_Tau','USTB10_PCT','T10Y3M_DFF','VIXCLS_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X4_vol = sm.add_constant(X4_vol)\n",
        "# Fit the OLS model\n",
        "model4 = sm.OLS(y1_US, X4_vol).fit()\n",
        "# print(model4.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 5\n",
        "X5_conf = df_reg_vars.loc[:,['NG_Delta_Tau','CCI_PCT','EPI_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X5_conf = sm.add_constant(X5_conf)\n",
        "# Fit the OLS model\n",
        "model5 = sm.OLS(y1_US, X5_conf).fit()\n",
        "# print(model5.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 6\n",
        "X6_epu = df_reg_vars.loc[:,['NG_Delta_Tau','USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X6_epu = sm.add_constant(X6_epu)\n",
        "# Fit the OLS model\n",
        "model6 = sm.OLS(y1_US, X6_epu).fit()\n",
        "# print(model6.summary())\n",
        "\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# model 7\n",
        "X7_all = df_reg_vars.loc[:,['NG_Delta_Tau', 'MSIMZMP_PCT', 'FEDFUNDS','ECBMLFR_DFF',\n",
        "                            'GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT',\n",
        "                            'USD_EURO_PCT','EUTB10_PCT', 'EURO_STOXX50_PCT','DAX30_PCT',\n",
        "                            'USTB10_PCT','VIXCLS_PCT',  'T10Y3M_DFF',\n",
        "                            'CCI_PCT','EPI_PCT',\n",
        "                            'USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X7_all = sm.add_constant(X7_all)\n",
        "# Fit the OLS model\n",
        "model7 = sm.OLS(y1_US, X7_all).fit()\n",
        "# print(model7.summary())\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 8\n",
        "X8_tone = df_reg_vars.loc[:,['NG_Delta_Tau']]\n",
        "\n",
        "# modeling the regression\n",
        "X8_tone = sm.add_constant(X8_tone)\n",
        "# Fit the OLS model\n",
        "model8 = sm.OLS(y1_US, X8_tone).fit()\n",
        "# print(model8.summary())\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# printing the results in more cleaner way\n",
        "from IPython.core.display import HTML\n",
        "from stargazer.stargazer import Stargazer\n",
        "\n",
        "# Assuming model1, model2, ..., model7 are your regression models\n",
        "stargazer = Stargazer([model1,model2,model3,model4,model5,model6, model7,model8])\n",
        "\n",
        "# Display the HTML table in Jupyter Notebook\n",
        "HTML(stargazer.render_html())\n",
        "\n",
        "# Save the HTML to a file\n",
        "with open('regression_results_NG_01.html', 'w') as file:\n",
        "    file.write(stargazer.render_html())\n",
        "\n"
      ],
      "metadata": {
        "id": "twpCjvHPq06R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 02: $\\delta\\phi$ and $R_t$"
      ],
      "metadata": {
        "id": "KkbqxhP-2-gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# y-variables along\n",
        "y1_US =df_reg_vars['S&P500_PCT']\n",
        "y2_EU =df_reg_vars['EURO_STOXX50_PCT']\n",
        "\n",
        "# x-variables along with the models (model 1)\n",
        "X1_policy = df_reg_vars.loc[:,['PS_Delta_Phi','FEDFUNDS','ECBMLFR_DFF', 'MSIMZMP_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X1_policy = sm.add_constant(X1_policy)\n",
        "# Fit the OLS model\n",
        "model1 = sm.OLS(y1_US, X1_policy).fit()\n",
        "# print(model1.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------\n",
        "\n",
        "# model 2\n",
        "X2_macs = df_reg_vars.loc[:,['PS_Delta_Phi','GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X2_macs = sm.add_constant(X2_macs)\n",
        "# Fit the OLS model\n",
        "model2 = sm.OLS(y1_US, X2_macs).fit()\n",
        "# print(model2.summary())\n",
        "\n",
        "# ----------------------------------------------\n",
        "\n",
        "\n",
        "# model 3\n",
        "X3_exts = df_reg_vars.loc[:,['PS_Delta_Phi','USD_EURO_PCT','EUTB10_PCT','EURO_STOXX50_PCT','DAX30_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X3_exts = sm.add_constant(X3_exts)\n",
        "# Fit the OLS model\n",
        "model3 = sm.OLS(y1_US, X3_exts).fit()\n",
        "# print(model3.summary())\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "\n",
        "# model 4\n",
        "X4_vol = df_reg_vars.loc[:,['PS_Delta_Phi','USTB10_PCT','T10Y3M_DFF','VIXCLS_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X4_vol = sm.add_constant(X4_vol)\n",
        "# Fit the OLS model\n",
        "model4 = sm.OLS(y1_US, X4_vol).fit()\n",
        "# print(model4.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 5\n",
        "X5_conf = df_reg_vars.loc[:,['PS_Delta_Phi','CCI_PCT','EPI_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X5_conf = sm.add_constant(X5_conf)\n",
        "# Fit the OLS model\n",
        "model5 = sm.OLS(y1_US, X5_conf).fit()\n",
        "# print(model5.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 6\n",
        "X6_epu = df_reg_vars.loc[:,['PS_Delta_Phi','USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X6_epu = sm.add_constant(X6_epu)\n",
        "# Fit the OLS model\n",
        "model6 = sm.OLS(y1_US, X6_epu).fit()\n",
        "# print(model6.summary())\n",
        "\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# model 7\n",
        "X7_all = df_reg_vars.loc[:,['PS_Delta_Phi','FEDFUNDS','ECBMLFR_DFF', 'MSIMZMP_PCT',\n",
        "                            'GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT',\n",
        "                            'USD_EURO_PCT','EUTB10_PCT','EURO_STOXX50_PCT','DAX30_PCT',\n",
        "                            'USTB10_PCT','T10Y3M_DFF','VIXCLS_PCT',\n",
        "                            'CCI_PCT','EPI_PCT',\n",
        "                            'USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "\n",
        "# modeling the regression\n",
        "X7_all = sm.add_constant(X7_all)\n",
        "# Fit the OLS model\n",
        "model7 = sm.OLS(y1_US, X7_all).fit()\n",
        "# print(model7.summary())\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# model 8\n",
        "X8_tone = df_reg_vars.loc[:,['PS_Delta_Phi']]\n",
        "\n",
        "# modeling the regression\n",
        "X8_tone = sm.add_constant(X8_tone)\n",
        "# Fit the OLS model\n",
        "model8 = sm.OLS(y1_US, X8_tone).fit()\n",
        "# print(model8.summary())\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# printing the results in more cleaner way\n",
        "from IPython.core.display import HTML\n",
        "from stargazer.stargazer import Stargazer\n",
        "\n",
        "# Assuming model1, model2, ..., model7 are your regression models\n",
        "stargazer = Stargazer([model1,model2,model3,model4,model5,model6, model7,model8])\n",
        "\n",
        "# Display the HTML table in Jupyter Notebook\n",
        "HTML(stargazer.render_html())\n",
        "\n",
        "# Save the HTML to a file\n",
        "with open('regression_results_PS_02.html', 'w') as file:\n",
        "    file.write(stargazer.render_html())\n",
        "\n"
      ],
      "metadata": {
        "id": "WGD8o_VciwtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3: $\\delta\\tau$ and $R_t$ Including the interaction Terms"
      ],
      "metadata": {
        "id": "94q03qNlgqeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# y-variables along\n",
        "y1_US =df_reg_vars['S&P500_PCT']\n",
        "y2_EU =df_reg_vars['EURO_STOXX50_PCT']\n",
        "\n",
        "# x-variables along with the models (model 1)\n",
        "X1_policy = df_reg_vars.loc[:,['NG_Delta_Tau','FEDFUNDS','ECBMLFR_DFF', 'MSIMZMP_PCT']]\n",
        "X1_policy['NGT_FED'] = X1_policy['NG_Delta_Tau']*X1_policy['FEDFUNDS']\n",
        "X1_policy['NGT_ECB'] = X1_policy['NG_Delta_Tau']*X1_policy['ECBMLFR_DFF']\n",
        "X1_policy['NGT_MSI'] = X1_policy['NG_Delta_Tau']*X1_policy['MSIMZMP_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X1_policy = sm.add_constant(X1_policy)\n",
        "# Fit the OLS model\n",
        "model1 = sm.OLS(y1_US, X1_policy).fit()\n",
        "print(model1.summary())\n",
        "\n",
        "# model 2\n",
        "X2_macs = df_reg_vars.loc[:,['NG_Delta_Tau','GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT']]\n",
        "X2_macs['NGT_CPI'] = X2_macs['NG_Delta_Tau']*X2_macs['CPIAUCSL_PCT']\n",
        "X2_macs['NGT_PPI'] = X2_macs['NG_Delta_Tau']*X2_macs['PPIACO_PCT']\n",
        "X2_macs['NGT_GDP'] = X2_macs['NG_Delta_Tau']*X2_macs['GDP_GROWTH']\n",
        "X2_macs['NGT_UNR'] = X2_macs['NG_Delta_Tau']*X2_macs['UNRATE']\n",
        "\n",
        "# modeling the regression\n",
        "X2_macs = sm.add_constant(X2_macs)\n",
        "# Fit the OLS model\n",
        "model2 = sm.OLS(y1_US, X2_macs).fit()\n",
        "print(model2.summary())\n",
        "\n",
        "# model 3\n",
        "X3_exts = df_reg_vars.loc[:,['NG_Delta_Tau','USD_EURO_PCT','EUTB10_PCT','EURO_STOXX50_PCT','DAX30_PCT']]\n",
        "X3_exts['NGT_USDEURO'] = X3_exts['NG_Delta_Tau']*X3_exts['USD_EURO_PCT']\n",
        "X3_exts['NGT_EUT10'] = X3_exts['NG_Delta_Tau']*X3_exts['EUTB10_PCT']\n",
        "X3_exts['NGT_EUSTM'] = X3_exts['NG_Delta_Tau']*X3_exts['EURO_STOXX50_PCT']\n",
        "X3_exts['NGT_DAX'] = X3_exts['NG_Delta_Tau']*X3_exts['DAX30_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X3_exts = sm.add_constant(X3_exts)\n",
        "# Fit the OLS model\n",
        "model3 = sm.OLS(y1_US, X3_exts).fit()\n",
        "print(model3.summary())\n",
        "\n",
        "# model 4\n",
        "X4_vol = df_reg_vars.loc[:,['NG_Delta_Tau','USTB10_PCT','T10Y3M_DFF','VIXCLS_PCT']]\n",
        "X4_vol['NGT_YSP'] = X4_vol['NG_Delta_Tau']*X4_vol['T10Y3M_DFF']\n",
        "X4_vol['NGT_VIX'] = X4_vol['NG_Delta_Tau']*X4_vol['VIXCLS_PCT']\n",
        "X4_vol['NGT_BVOL'] = X4_vol['NG_Delta_Tau']*X4_vol['USTB10_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X4_vol = sm.add_constant(X4_vol)\n",
        "# Fit the OLS model\n",
        "model4 = sm.OLS(y1_US, X4_vol).fit()\n",
        "# print(model4.summary())\n",
        "\n",
        "# model 5\n",
        "X5_conf = df_reg_vars.loc[:,['NG_Delta_Tau','CCI_PCT','EPI_PCT']]\n",
        "X5_conf['NGT_CCONF'] = X5_conf['NG_Delta_Tau']*X5_conf['CCI_PCT']\n",
        "X5_conf['NGT_ECONF'] = X5_conf['NG_Delta_Tau']*X5_conf['EPI_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X5_conf = sm.add_constant(X5_conf)\n",
        "# Fit the OLS model\n",
        "model5 = sm.OLS(y1_US, X5_conf).fit()\n",
        "# print(model5.summary())\n",
        "\n",
        "# model 6\n",
        "X6_epu = df_reg_vars.loc[:,['NG_Delta_Tau','USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "X6_epu['NGT_EPU'] = X6_epu['NG_Delta_Tau']*X6_epu['USEPUINDXD_PCT']\n",
        "X6_epu['NGT_ESENT'] = X6_epu['NG_Delta_Tau']*X6_epu['UMCSENT_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X6_epu = sm.add_constant(X6_epu)\n",
        "# Fit the OLS model\n",
        "model6 = sm.OLS(y1_US, X6_epu).fit()\n",
        "# print(model6.summary())\n",
        "\n",
        "# printing the results in more cleaner way\n",
        "from IPython.core.display import HTML\n",
        "from stargazer.stargazer import Stargazer\n",
        "\n",
        "# Assuming model1, model2, ..., model6 are your regression models\n",
        "stargazer = Stargazer([model1,model2,model3,model4,model5,model6])\n",
        "\n",
        "# Display the HTML table in Jupyter Notebook\n",
        "HTML(stargazer.render_html())\n",
        "\n",
        "# Save the HTML to a file\n",
        "with open('regression_results_NG_Interact_01.html', 'w') as file:\n",
        "    file.write(stargazer.render_html())\n"
      ],
      "metadata": {
        "id": "S0tgxXlHgmKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4: $\\delta\\phi$ and $R_t$ Including the interaction Terms"
      ],
      "metadata": {
        "id": "CFeXKsNMXndg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# y-variables along\n",
        "y1_US =df_reg_vars['S&P500_PCT']\n",
        "y2_EU =df_reg_vars['EURO_STOXX50_PCT']\n",
        "\n",
        "# x-variables along with the models (model 1)\n",
        "X1_policy = df_reg_vars.loc[:,['PS_Delta_Phi','FEDFUNDS','ECBMLFR_DFF', 'MSIMZMP_PCT']]\n",
        "X1_policy['NGT_FED'] = X1_policy['PS_Delta_Phi']*X1_policy['FEDFUNDS']\n",
        "X1_policy['NGT_ECB'] = X1_policy['PS_Delta_Phi']*X1_policy['ECBMLFR_DFF']\n",
        "X1_policy['NGT_MSI'] = X1_policy['PS_Delta_Phi']*X1_policy['MSIMZMP_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X1_policy = sm.add_constant(X1_policy)\n",
        "# Fit the OLS model\n",
        "model1 = sm.OLS(y1_US, X1_policy).fit()\n",
        "print(model1.summary())\n",
        "\n",
        "# model 2\n",
        "X2_macs = df_reg_vars.loc[:,['PS_Delta_Phi','GDP_GROWTH','UNRATE','CPIAUCSL_PCT','Export_YOY','PPIACO_PCT','CRUDE_OIL_PCT','GOLD_PCT']]\n",
        "X2_macs['NGT_CPI'] = X2_macs['PS_Delta_Phi']*X2_macs['CPIAUCSL_PCT']\n",
        "X2_macs['NGT_PPI'] = X2_macs['PS_Delta_Phi']*X2_macs['PPIACO_PCT']\n",
        "X2_macs['NGT_GDP'] = X2_macs['PS_Delta_Phi']*X2_macs['GDP_GROWTH']\n",
        "X2_macs['NGT_UNR'] = X2_macs['PS_Delta_Phi']*X2_macs['UNRATE']\n",
        "\n",
        "# modeling the regression\n",
        "X2_macs = sm.add_constant(X2_macs)\n",
        "# Fit the OLS model\n",
        "model2 = sm.OLS(y1_US, X2_macs).fit()\n",
        "print(model2.summary())\n",
        "\n",
        "# model 3\n",
        "X3_exts = df_reg_vars.loc[:,['PS_Delta_Phi','USD_EURO_PCT','EUTB10_PCT','EURO_STOXX50_PCT','DAX30_PCT']]\n",
        "X3_exts['NGT_USDEURO'] = X3_exts['PS_Delta_Phi']*X3_exts['USD_EURO_PCT']\n",
        "X3_exts['NGT_EUT10'] = X3_exts['PS_Delta_Phi']*X3_exts['EUTB10_PCT']\n",
        "X3_exts['NGT_EUSTM'] = X3_exts['PS_Delta_Phi']*X3_exts['EURO_STOXX50_PCT']\n",
        "X3_exts['NGT_DAX'] = X3_exts['PS_Delta_Phi']*X3_exts['DAX30_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X3_exts = sm.add_constant(X3_exts)\n",
        "# Fit the OLS model\n",
        "model3 = sm.OLS(y1_US, X3_exts).fit()\n",
        "print(model3.summary())\n",
        "\n",
        "# model 4\n",
        "X4_vol = df_reg_vars.loc[:,['PS_Delta_Phi','USTB10_PCT','T10Y3M_DFF','VIXCLS_PCT']]\n",
        "X4_vol['NGT_YSP'] = X4_vol['PS_Delta_Phi']*X4_vol['T10Y3M_DFF']\n",
        "X4_vol['NGT_VIX'] = X4_vol['PS_Delta_Phi']*X4_vol['VIXCLS_PCT']\n",
        "X4_vol['NGT_BVOL'] = X4_vol['PS_Delta_Phi']*X4_vol['USTB10_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X4_vol = sm.add_constant(X4_vol)\n",
        "# Fit the OLS model\n",
        "model4 = sm.OLS(y1_US, X4_vol).fit()\n",
        "# print(model4.summary())\n",
        "\n",
        "# model 5\n",
        "X5_conf = df_reg_vars.loc[:,['PS_Delta_Phi','CCI_PCT','EPI_PCT']]\n",
        "X5_conf['NGT_CCONF'] = X5_conf['PS_Delta_Phi']*X5_conf['CCI_PCT']\n",
        "X5_conf['NGT_ECONF'] = X5_conf['PS_Delta_Phi']*X5_conf['EPI_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X5_conf = sm.add_constant(X5_conf)\n",
        "# Fit the OLS model\n",
        "model5 = sm.OLS(y1_US, X5_conf).fit()\n",
        "# print(model5.summary())\n",
        "\n",
        "# model 6\n",
        "X6_epu = df_reg_vars.loc[:,['PS_Delta_Phi','USEPUINDXD_PCT','UMCSENT_PCT']]\n",
        "X6_epu['NGT_EPU'] = X6_epu['PS_Delta_Phi']*X6_epu['USEPUINDXD_PCT']\n",
        "X6_epu['NGT_ESENT'] = X6_epu['PS_Delta_Phi']*X6_epu['UMCSENT_PCT']\n",
        "\n",
        "# modeling the regression\n",
        "X6_epu = sm.add_constant(X6_epu)\n",
        "# Fit the OLS model\n",
        "model6 = sm.OLS(y1_US, X6_epu).fit()\n",
        "# print(model6.summary())\n",
        "\n",
        "\n",
        "# printing the results in more cleaner way\n",
        "from IPython.core.display import HTML\n",
        "from stargazer.stargazer import Stargazer\n",
        "\n",
        "# Assuming model1, model2, ..., model6 are your regression models\n",
        "stargazer = Stargazer([model1,model2,model3,model4,model5,model6])\n",
        "\n",
        "# Display the HTML table in Jupyter Notebook\n",
        "HTML(stargazer.render_html())\n",
        "\n",
        "# Save the HTML to a file\n",
        "with open('regression_results_PS_Interact_02.html', 'w') as file:\n",
        "    file.write(stargazer.render_html())\n"
      ],
      "metadata": {
        "id": "9KtCYHmQU_uh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}